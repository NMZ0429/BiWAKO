{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"0. Introduction This repository offers Models : Trained state-of-the-art models for various vision tasks in ONNXRuntime backend No-Code Modules : Easy interface to use those models for both prediction and visualizing output. No coding is needed. The interface is universal among all models in this library. Extentiability : Customizable modules to use it for applications such as realtime inference. 1. Installation Install directly from this repository. $cd BiWAKO $pip install -e . Warning Downloading from pip server is currently suspended in order to protect weight files. We will update it soon. 2. Usage No matter which model you use, these interface is the same. Instantiate model with BiWAKO.ModelName(weight) . The corresponding ModelName and weight to the task you want to work on can be found at the table in the next section. Weight file is automaticaly downloaded. call predict(image) . image can be either path to the image or cv2 image array. call render(prediction, image) . prediction is the return value of predict() method and image is the same as above. Some model takes optional arguments to control details in the output. import BiWAKO # 1. Initialize Model model = BiWAKO . MiDAS ( model = \"mono_depth_small\" ) # 2. Feed Image (accept cv2 image or path to the image) prediction = model . predict ( image_or_image_path ) # 3. Visiualize result as a cv2 image result_img = model . render ( prediction , image_or_image_path ) 4. Models The following list is the current availability of models with weight variations. Click the link at the model column for futher documentation. Task Model Weights Mono Depth Prediction MiDAS mono_depth_small-mono_depth_large Salient Object Detection U2Net Basic-Mobile-Human Super Resolution RealESRGAN Large-Small Object Detection YOLO nano-s-large-extreme Emotion Prediction FerPlus ferplus8 Human Parsing HumanParsing human_attribute Denoise HINet denoise_320_480 Face Detection YuNet yunet_120_160 Style Transfer AnimeGAN animeGAN512 Image Classification ResNetV2 resnet152v2-resnet101v2-resnet50v2-resnet18v2 Human Portrait Segmentation MODNet modnet_256 5. Deployment It is extremely easy to use BiWAKO at application layer. 1. Real Time Prediction Any model can be used in the same way to run real-time inference. 2. FastAPI Implementation Like the above example, you can build simple Backend API for inference on web server.","title":"Home"},{"location":"#_1","text":"","title":""},{"location":"#0-introduction","text":"This repository offers Models : Trained state-of-the-art models for various vision tasks in ONNXRuntime backend No-Code Modules : Easy interface to use those models for both prediction and visualizing output. No coding is needed. The interface is universal among all models in this library. Extentiability : Customizable modules to use it for applications such as realtime inference.","title":"0. Introduction"},{"location":"#1-installation","text":"Install directly from this repository. $cd BiWAKO $pip install -e . Warning Downloading from pip server is currently suspended in order to protect weight files. We will update it soon.","title":"1. Installation"},{"location":"#2-usage","text":"No matter which model you use, these interface is the same. Instantiate model with BiWAKO.ModelName(weight) . The corresponding ModelName and weight to the task you want to work on can be found at the table in the next section. Weight file is automaticaly downloaded. call predict(image) . image can be either path to the image or cv2 image array. call render(prediction, image) . prediction is the return value of predict() method and image is the same as above. Some model takes optional arguments to control details in the output. import BiWAKO # 1. Initialize Model model = BiWAKO . MiDAS ( model = \"mono_depth_small\" ) # 2. Feed Image (accept cv2 image or path to the image) prediction = model . predict ( image_or_image_path ) # 3. Visiualize result as a cv2 image result_img = model . render ( prediction , image_or_image_path )","title":"2. Usage"},{"location":"#4-models","text":"The following list is the current availability of models with weight variations. Click the link at the model column for futher documentation. Task Model Weights Mono Depth Prediction MiDAS mono_depth_small-mono_depth_large Salient Object Detection U2Net Basic-Mobile-Human Super Resolution RealESRGAN Large-Small Object Detection YOLO nano-s-large-extreme Emotion Prediction FerPlus ferplus8 Human Parsing HumanParsing human_attribute Denoise HINet denoise_320_480 Face Detection YuNet yunet_120_160 Style Transfer AnimeGAN animeGAN512 Image Classification ResNetV2 resnet152v2-resnet101v2-resnet50v2-resnet18v2 Human Portrait Segmentation MODNet modnet_256","title":"4. Models"},{"location":"#5-deployment","text":"It is extremely easy to use BiWAKO at application layer. 1. Real Time Prediction Any model can be used in the same way to run real-time inference. 2. FastAPI Implementation Like the above example, you can build simple Backend API for inference on web server.","title":"5. Deployment"},{"location":"denoising/","text":"HINet BiWAKO.denoise.HINet ( BaseInference ) HINet for denoising image. Attributes: Name Type Description model InferenceSession ONNX model. input_name str Name of input node. input_shape tuple Shape of input node. __init__ ( self , model = 'denoise_320_480' ) special Initialize HINet. Parameters: Name Type Description Default model str Choise of model. Weight file is automatically downloaded to the current directory at the first time. Defaults to \"denoise_320_480.onnx\". 'denoise_320_480' predict ( self , image ) Return denoised image. Parameters: Name Type Description Default image Image Image to be denoised in str or cv2 format. required Returns: Type Description np.ndarray Denoised image array containing two images for different denoising methods. render ( self , prediction , image = None , output_type = 0 , output_shape = None ) Return the denoised image in original image size. Parameters: Name Type Description Default prediction np.ndarray Return value of predict(). required image Image Image to be processed in str or cv2 format. Defaults to None. None output_type Literal[0, 1] Choice of denoising method either 0 or 1. Defaults to 0. 0 output_shape Optional[Tuple[int, int]] Optional tuple of int to resize the return image. Defaults to None. None Exceptions: Type Description ValueError If none of the original image or image size is given. ValueError If output_type is not 0 or 1. Returns: Type Description np.ndarray Denoised image in cv2 format.","title":"Denoise Image"},{"location":"denoising/#hinet","text":"","title":"HINet"},{"location":"denoising/#BiWAKO.denoise.HINet","text":"HINet for denoising image. Attributes: Name Type Description model InferenceSession ONNX model. input_name str Name of input node. input_shape tuple Shape of input node.","title":"HINet"},{"location":"denoising/#BiWAKO.denoise.HINet.__init__","text":"Initialize HINet. Parameters: Name Type Description Default model str Choise of model. Weight file is automatically downloaded to the current directory at the first time. Defaults to \"denoise_320_480.onnx\". 'denoise_320_480'","title":"__init__()"},{"location":"denoising/#BiWAKO.denoise.HINet.predict","text":"Return denoised image. Parameters: Name Type Description Default image Image Image to be denoised in str or cv2 format. required Returns: Type Description np.ndarray Denoised image array containing two images for different denoising methods.","title":"predict()"},{"location":"denoising/#BiWAKO.denoise.HINet.render","text":"Return the denoised image in original image size. Parameters: Name Type Description Default prediction np.ndarray Return value of predict(). required image Image Image to be processed in str or cv2 format. Defaults to None. None output_type Literal[0, 1] Choice of denoising method either 0 or 1. Defaults to 0. 0 output_shape Optional[Tuple[int, int]] Optional tuple of int to resize the return image. Defaults to None. None Exceptions: Type Description ValueError If none of the original image or image size is given. ValueError If output_type is not 0 or 1. Returns: Type Description np.ndarray Denoised image in cv2 format.","title":"render()"},{"location":"emotion/","text":"Emotion Recognition BiWAKO.emotion_prediction.FerPlus ( BaseInference ) Emotion prediction model. The model requires the input image to be trimmed around the face. Use YuNet to detect the face and crop the image around it. Attributes: Name Type Description model_path str Path to the model weights. If automatic download is triggered, this path is used to save the model. session onnxruntime.InferenceSession The inference session. input_name str The name of the input node. output_name str The name of the output node. emotion_table list A list of emotions trained. __init__ ( self , model = 'ferplus8' ) special Initialize the model. Parameters: Name Type Description Default model str The name of the model. Also accept the path to the onnx file. If not found, the model will be downloaded. Currently only support \"ferplus8\". 'ferplus8' predict ( self , image ) Return the array of the confidences of each predction. Parameters: Name Type Description Default image Image Image to be processed. Accept the path to the image or cv2 image. required Returns: Type Description np.ndarray The array of the confidences of each predction. render ( self , prediction , image ) Return the list of emotions and their confidences in string. This method is currently under the development. Parameters: Name Type Description Default prediction np.ndarray The array of the confidences of each predction. required image Image Image to be processed. Accept the path to the image or cv2 image. Not actually required. required Returns: Type Description np.ndarray The list of emotions and their confidences in string.","title":"Emotion Recognition"},{"location":"emotion/#emotion-recognition","text":"","title":"Emotion Recognition"},{"location":"emotion/#BiWAKO.emotion_prediction.FerPlus","text":"Emotion prediction model. The model requires the input image to be trimmed around the face. Use YuNet to detect the face and crop the image around it. Attributes: Name Type Description model_path str Path to the model weights. If automatic download is triggered, this path is used to save the model. session onnxruntime.InferenceSession The inference session. input_name str The name of the input node. output_name str The name of the output node. emotion_table list A list of emotions trained.","title":"FerPlus"},{"location":"emotion/#BiWAKO.emotion_prediction.FerPlus.__init__","text":"Initialize the model. Parameters: Name Type Description Default model str The name of the model. Also accept the path to the onnx file. If not found, the model will be downloaded. Currently only support \"ferplus8\". 'ferplus8'","title":"__init__()"},{"location":"emotion/#BiWAKO.emotion_prediction.FerPlus.predict","text":"Return the array of the confidences of each predction. Parameters: Name Type Description Default image Image Image to be processed. Accept the path to the image or cv2 image. required Returns: Type Description np.ndarray The array of the confidences of each predction.","title":"predict()"},{"location":"emotion/#BiWAKO.emotion_prediction.FerPlus.render","text":"Return the list of emotions and their confidences in string. This method is currently under the development. Parameters: Name Type Description Default prediction np.ndarray The array of the confidences of each predction. required image Image Image to be processed. Accept the path to the image or cv2 image. Not actually required. required Returns: Type Description np.ndarray The list of emotions and their confidences in string.","title":"render()"},{"location":"face_det/","text":"Face Detection BiWAKO.face_detection.YuNet ( BaseInference ) Face Detection model. Attributes: Name Type Description model onnxruntime.InferenceSession ONNX model. input_name str name of input node. output_names list names of three output nodes. input_shape list shape of input image. Set to [160, 120] by default. conf_th float confidence threshold. Set to 0.6 by default. nms_th float non-maximum suppression threshold. Set to 0.3 by default. topk int keep top-k results. Set to 5000 by default. priors np.ndarray prior boxes. __init__ ( self , model = 'yunet_120_160' , input_shape = [ 160 , 120 ], conf_th = 0.6 , nms_th = 0.3 , topk = 5000 , keep_topk = 750 ) special Initialize YuNet. Parameters: Name Type Description Default model Literal[\"yunet_120_160\"] Choice of model or path to onnx file. Defaults to yunet_120_160. 'yunet_120_160' input_shape list Input image shape. Defaults to [160, 120]. [160, 120] conf_th float Confidence level threshold. Defaults to 0.6. 0.6 nms_th float NMS threshold. Defaults to 0.3. 0.3 topk int Number of faces to detect. Defaults to 5000. 5000 keep_topk int Number of predictions to save. Defaults to 750. 750 predict ( self , image ) Return the face detection result. The prediction result is a tuple of three lists. First list is bounding boxes, second list is landmarks, and third list is scores. For example, accesing 2nd parson's bounding box is done by prediction [1][0] , and prediction [1][1] is landmarks of 2nd person. Parameters: Name Type Description Default image Image image to be detected. Accept path or cv2 image. required Returns: Type Description Tuple[list, list, list] Tuple of three lists of bounding box, landmark, and score. render ( self , prediction , image ) Render the bounding box and landmarks on the original image. Parameters: Name Type Description Default prediction tuple prediction result returned by predict(). required image Image original image in str or cv2 image. required Returns: Type Description np.ndarray Original image with bounding box and landmarks.","title":"Face Detection"},{"location":"face_det/#face-detection","text":"","title":"Face Detection"},{"location":"face_det/#BiWAKO.face_detection.YuNet","text":"Face Detection model. Attributes: Name Type Description model onnxruntime.InferenceSession ONNX model. input_name str name of input node. output_names list names of three output nodes. input_shape list shape of input image. Set to [160, 120] by default. conf_th float confidence threshold. Set to 0.6 by default. nms_th float non-maximum suppression threshold. Set to 0.3 by default. topk int keep top-k results. Set to 5000 by default. priors np.ndarray prior boxes.","title":"YuNet"},{"location":"face_det/#BiWAKO.face_detection.YuNet.__init__","text":"Initialize YuNet. Parameters: Name Type Description Default model Literal[\"yunet_120_160\"] Choice of model or path to onnx file. Defaults to yunet_120_160. 'yunet_120_160' input_shape list Input image shape. Defaults to [160, 120]. [160, 120] conf_th float Confidence level threshold. Defaults to 0.6. 0.6 nms_th float NMS threshold. Defaults to 0.3. 0.3 topk int Number of faces to detect. Defaults to 5000. 5000 keep_topk int Number of predictions to save. Defaults to 750. 750","title":"__init__()"},{"location":"face_det/#BiWAKO.face_detection.YuNet.predict","text":"Return the face detection result. The prediction result is a tuple of three lists. First list is bounding boxes, second list is landmarks, and third list is scores. For example, accesing 2nd parson's bounding box is done by prediction [1][0] , and prediction [1][1] is landmarks of 2nd person. Parameters: Name Type Description Default image Image image to be detected. Accept path or cv2 image. required Returns: Type Description Tuple[list, list, list] Tuple of three lists of bounding box, landmark, and score.","title":"predict()"},{"location":"face_det/#BiWAKO.face_detection.YuNet.render","text":"Render the bounding box and landmarks on the original image. Parameters: Name Type Description Default prediction tuple prediction result returned by predict(). required image Image original image in str or cv2 image. required Returns: Type Description np.ndarray Original image with bounding box and landmarks.","title":"render()"},{"location":"human_parsing/","text":"Human Parsing BiWAKO.human_attribute.HumanParsing ( BaseInference ) Basic ResNet50 model for parsing attributes of pedestrians Attributes: Name Type Description model onnxruntime.InferenceSession ONNXRuntime instance. conf_thresh float confidence threshold for prediction. input_name str name of input node. output_name str name of output node. input_shape tuple shape of input node. labels np.ndarray mapping of label index to label name. predict ( self , image ) Return the prediction on the image. Parameters: Name Type Description Default image Image image to be processed in str or cv2 format. required Returns: Type Description np.ndarray processed image render ( self , prediction , image ) Return the original image with the prediction at the top left corner. Parameters: Name Type Description Default prediction np.ndarray prediction of the model. required image Image image to be rendered in str or cv2 format. required Returns: Type Description np.ndarray rendered image","title":"Human Parsing"},{"location":"human_parsing/#human-parsing","text":"","title":"Human Parsing"},{"location":"human_parsing/#BiWAKO.human_attribute.HumanParsing","text":"Basic ResNet50 model for parsing attributes of pedestrians Attributes: Name Type Description model onnxruntime.InferenceSession ONNXRuntime instance. conf_thresh float confidence threshold for prediction. input_name str name of input node. output_name str name of output node. input_shape tuple shape of input node. labels np.ndarray mapping of label index to label name.","title":"HumanParsing"},{"location":"human_parsing/#BiWAKO.human_attribute.HumanParsing.predict","text":"Return the prediction on the image. Parameters: Name Type Description Default image Image image to be processed in str or cv2 format. required Returns: Type Description np.ndarray processed image","title":"predict()"},{"location":"human_parsing/#BiWAKO.human_attribute.HumanParsing.render","text":"Return the original image with the prediction at the top left corner. Parameters: Name Type Description Default prediction np.ndarray prediction of the model. required image Image image to be rendered in str or cv2 format. required Returns: Type Description np.ndarray rendered image","title":"render()"},{"location":"human_seg/","text":"Human Portrait Segmentation BiWAKO.human_seg.MODNet ( BaseInference ) Segmentation model trained on human portrait image. Attributes: Name Type Description model onnxruntime.InferenceSession Inference session. input_name str Name of input node. output_name str Name of output node. input_shape tuple Size of input image. score_th float Threshold for mask. __init__ ( self , model = 'modnet_256' , score_th = 0.5 ) special Initialize MODNet. Parameters: Name Type Description Default model str Choice of model or path to the onnx file. Defaults to \"modnet_256\". If chosen model has not been downloaded, it will be downloaded automatically. 'modnet_256' score_th float Optional threshold for mask used in self.render(). Any pixels in the mask with confidence score lower than this value will be set to 0. Defaults to 0.5. 0.5 _preprocess ( self , image ) private Preprocess image for inference. This is automatically called by predict(). Preprocess Resize image to the same size as the model input. Normalize image to [-1, 1] with mean and std of 0.5. Convert image to float32 and reshape to (1, C, H, W). Parameters: Name Type Description Default image np.ndarray Image in cv2 format. required Returns: Type Description np.ndarray Preprocessed image in numpy format. predict ( self , image ) Return mask of given image. Parameters: Name Type Description Default image Image Image to be segmented. Accept path to image or cv2 image. required Returns: Type Description np.ndarray Predicted mask in original size. render ( self , prediction , image , score_th = None , ** kwargs ) Apply the mask to the input image. Parameters: Name Type Description Default prediction np.ndarray Mask returned by predict(). required image Image Image to be segmented. Accept path to image or cv2 image. required score_th float Optional threshold for mask. Defaults to use the value set in the constructor. None Returns: Type Description np.ndarray Segmented image in cv2 format. Reference https://github.com/ZHKKKe/MODNet/blob/master/onnx/inference_onnx.py","title":"Human Portrait Segmentation"},{"location":"human_seg/#human-portrait-segmentation","text":"","title":"Human Portrait Segmentation"},{"location":"human_seg/#BiWAKO.human_seg.MODNet","text":"Segmentation model trained on human portrait image. Attributes: Name Type Description model onnxruntime.InferenceSession Inference session. input_name str Name of input node. output_name str Name of output node. input_shape tuple Size of input image. score_th float Threshold for mask.","title":"MODNet"},{"location":"human_seg/#BiWAKO.human_seg.MODNet.__init__","text":"Initialize MODNet. Parameters: Name Type Description Default model str Choice of model or path to the onnx file. Defaults to \"modnet_256\". If chosen model has not been downloaded, it will be downloaded automatically. 'modnet_256' score_th float Optional threshold for mask used in self.render(). Any pixels in the mask with confidence score lower than this value will be set to 0. Defaults to 0.5. 0.5","title":"__init__()"},{"location":"human_seg/#BiWAKO.human_seg.MODNet._preprocess","text":"Preprocess image for inference. This is automatically called by predict(). Preprocess Resize image to the same size as the model input. Normalize image to [-1, 1] with mean and std of 0.5. Convert image to float32 and reshape to (1, C, H, W). Parameters: Name Type Description Default image np.ndarray Image in cv2 format. required Returns: Type Description np.ndarray Preprocessed image in numpy format.","title":"_preprocess()"},{"location":"human_seg/#BiWAKO.human_seg.MODNet.predict","text":"Return mask of given image. Parameters: Name Type Description Default image Image Image to be segmented. Accept path to image or cv2 image. required Returns: Type Description np.ndarray Predicted mask in original size.","title":"predict()"},{"location":"human_seg/#BiWAKO.human_seg.MODNet.render","text":"Apply the mask to the input image. Parameters: Name Type Description Default prediction np.ndarray Mask returned by predict(). required image Image Image to be segmented. Accept path to image or cv2 image. required score_th float Optional threshold for mask. Defaults to use the value set in the constructor. None Returns: Type Description np.ndarray Segmented image in cv2 format.","title":"render()"},{"location":"human_seg/#reference","text":"https://github.com/ZHKKKe/MODNet/blob/master/onnx/inference_onnx.py","title":"Reference"},{"location":"image_clf/","text":"Image Classification BiWAKO.image_classification.ResNet ( BaseInference ) Basic ResNet V2 trained on ImageNet Attributes: Name Type Description model_path str Path to the model file. If automatic download is not enabled, this path is used to save the file. model onnxruntime.InferenceSession Inference session for the model. input_name str Name of the input node. output_name str Name of the output node. input_shape tuple Shape of the input node. label dict Dictionary of the label. The key is the class index and the value is the class name. mean np.ndarray Mean of the normalization. var np.ndarray Variance of the normalization. __init__ ( self , model = 'resnet18v2' ) special Initialize ResNet Available models: \"resnet152v2\" \"resnet101v2\" \"resnet50v2\" or \"resnet18v2\" Parameters: Name Type Description Default model str Choice of the model from the table above or path to the downloaded onnx file. If the file has not been downloaded, the automatic download is triggered. Defaults to \"resnet18v2\". 'resnet18v2' predict ( self , image ) Return the prediction of the model Parameters: Name Type Description Default image Image Image to be predicted. Accept path or cv2 image. required Returns: Type Description np.ndarray 1 by 1000 array of the prediction. Softmax is not applied. render ( self , prediction , image , topk = 5 , ** kwargs ) Return the original image with the predicted class names Parameters: Name Type Description Default prediction np.ndarray Prediction returned by predict(). required image Image Image to be predicted. Accept path or cv2 image. required topk int Number of classes to display with higher probability. Defaults to 5. 5 Returns: Type Description np.ndarray Image with the predicted class names.","title":"Image Classification"},{"location":"image_clf/#image-classification","text":"","title":"Image Classification"},{"location":"image_clf/#BiWAKO.image_classification.ResNet","text":"Basic ResNet V2 trained on ImageNet Attributes: Name Type Description model_path str Path to the model file. If automatic download is not enabled, this path is used to save the file. model onnxruntime.InferenceSession Inference session for the model. input_name str Name of the input node. output_name str Name of the output node. input_shape tuple Shape of the input node. label dict Dictionary of the label. The key is the class index and the value is the class name. mean np.ndarray Mean of the normalization. var np.ndarray Variance of the normalization.","title":"ResNet"},{"location":"image_clf/#BiWAKO.image_classification.ResNet.__init__","text":"Initialize ResNet Available models: \"resnet152v2\" \"resnet101v2\" \"resnet50v2\" or \"resnet18v2\" Parameters: Name Type Description Default model str Choice of the model from the table above or path to the downloaded onnx file. If the file has not been downloaded, the automatic download is triggered. Defaults to \"resnet18v2\". 'resnet18v2'","title":"__init__()"},{"location":"image_clf/#BiWAKO.image_classification.ResNet.predict","text":"Return the prediction of the model Parameters: Name Type Description Default image Image Image to be predicted. Accept path or cv2 image. required Returns: Type Description np.ndarray 1 by 1000 array of the prediction. Softmax is not applied.","title":"predict()"},{"location":"image_clf/#BiWAKO.image_classification.ResNet.render","text":"Return the original image with the predicted class names Parameters: Name Type Description Default prediction np.ndarray Prediction returned by predict(). required image Image Image to be predicted. Accept path or cv2 image. required topk int Number of classes to display with higher probability. Defaults to 5. 5 Returns: Type Description np.ndarray Image with the predicted class names.","title":"render()"},{"location":"mono_depth/","text":"Mono Depth Prediction BiWAKO.mono_depth.MiDAS ( BaseInference ) MonoDepth prediction model. Attributes: Name Type Description model_path str Path to model file. If automatic download is triggered, this path is used to save the model. session onnxruntime.InferenceSession Inference session. input_name str Input node name. output_name str Output node name. input_shape tuple Input shape. h int Alias of input_shape[2]. w int Alias of input_shape[3]. __init__ ( self , model = 'mono_depth_small' , show_exp = False ) special Initialize model. Parameters: Name Type Description Default model Literal[\"mono_depth_small\", \"mono_depth_large\"] Model name. Defaults to \"mono_depth_small\". Onnx file is downloaded automatically. 'mono_depth_small' show_exp bool True to display expected input size. Defaults to False. False predict ( self , img ) Predict. Parameters: Name Type Description Default img Union[str, np.ndarray] image path or numpy array in cv2 format required Returns: Type Description np.ndarray predicted depthmap render ( self , prediction , query ) Return the resized depth map in cv2 foramt. Parameters: Name Type Description Default prediction np.ndarray predicted depthmap required query Union[str, np.ndarray] query image path or numpy array in cv2 format used for resizing. required Returns: Type Description np.ndarray Resized depthmap","title":"Mono Depth Prediction"},{"location":"mono_depth/#mono-depth-prediction","text":"","title":"Mono Depth Prediction"},{"location":"mono_depth/#BiWAKO.mono_depth.MiDAS","text":"MonoDepth prediction model. Attributes: Name Type Description model_path str Path to model file. If automatic download is triggered, this path is used to save the model. session onnxruntime.InferenceSession Inference session. input_name str Input node name. output_name str Output node name. input_shape tuple Input shape. h int Alias of input_shape[2]. w int Alias of input_shape[3].","title":"MiDAS"},{"location":"mono_depth/#BiWAKO.mono_depth.MiDAS.__init__","text":"Initialize model. Parameters: Name Type Description Default model Literal[\"mono_depth_small\", \"mono_depth_large\"] Model name. Defaults to \"mono_depth_small\". Onnx file is downloaded automatically. 'mono_depth_small' show_exp bool True to display expected input size. Defaults to False. False","title":"__init__()"},{"location":"mono_depth/#BiWAKO.mono_depth.MiDAS.predict","text":"Predict. Parameters: Name Type Description Default img Union[str, np.ndarray] image path or numpy array in cv2 format required Returns: Type Description np.ndarray predicted depthmap","title":"predict()"},{"location":"mono_depth/#BiWAKO.mono_depth.MiDAS.render","text":"Return the resized depth map in cv2 foramt. Parameters: Name Type Description Default prediction np.ndarray predicted depthmap required query Union[str, np.ndarray] query image path or numpy array in cv2 format used for resizing. required Returns: Type Description np.ndarray Resized depthmap","title":"render()"},{"location":"obj_det/","text":"YOLO BiWAKO.object_detection.YOLO ( BaseInference ) YOLOv5 onnx model. Attributes: Name Type Description model_path str Path to the onnx file. If auto download is triggered, the file is downloaded to this path. session onnxruntime.InferenceSession Inference session. input_name str Name of the input node. output_name str Name of the output node. input_shape tuple Shape of the input image. Set accordingly to the model. coco_label list List of coco 80 labels. colors Colors Color palette written by Ultralytics at https://github.com/ultralytics/yolov5/blob/a3d5f1d3e36d8e023806da0f0c744eef02591c9b/utils/plots.py __init__ ( self , model = 'yolo_nano' ) special Initialize the model. Parameters: Name Type Description Default model Literal[\"yolo_nano\", \"yolo_s\", \"yolo_xl\", \"yolo_extreme\"] Model type to be used. Also accept path to the onnx file. If the model is not found, it will be downloaded automatically. 'yolo_nano' predict ( self , image ) Return the prediction of the model. Parameters: Name Type Description Default image Image Image to be predicted. Accept str or cv2 image. required Returns: Type Description np.ndarray n by 6 array where 2nd dimension is xyxy with label and confidence. render ( self , prediction , image ) Return the original image with predicted bounding boxes. Parameters: Name Type Description Default prediction np.ndarray Prediction of the model. required image Image Image to be predicted. Accept str or cv2 image. required Returns: Type Description np.ndarray Image with predicted bounding boxes in cv2 format.","title":"Object Detection"},{"location":"obj_det/#yolo","text":"","title":"YOLO"},{"location":"obj_det/#BiWAKO.object_detection.YOLO","text":"YOLOv5 onnx model. Attributes: Name Type Description model_path str Path to the onnx file. If auto download is triggered, the file is downloaded to this path. session onnxruntime.InferenceSession Inference session. input_name str Name of the input node. output_name str Name of the output node. input_shape tuple Shape of the input image. Set accordingly to the model. coco_label list List of coco 80 labels. colors Colors Color palette written by Ultralytics at https://github.com/ultralytics/yolov5/blob/a3d5f1d3e36d8e023806da0f0c744eef02591c9b/utils/plots.py","title":"YOLO"},{"location":"obj_det/#BiWAKO.object_detection.YOLO.__init__","text":"Initialize the model. Parameters: Name Type Description Default model Literal[\"yolo_nano\", \"yolo_s\", \"yolo_xl\", \"yolo_extreme\"] Model type to be used. Also accept path to the onnx file. If the model is not found, it will be downloaded automatically. 'yolo_nano'","title":"__init__()"},{"location":"obj_det/#BiWAKO.object_detection.YOLO.predict","text":"Return the prediction of the model. Parameters: Name Type Description Default image Image Image to be predicted. Accept str or cv2 image. required Returns: Type Description np.ndarray n by 6 array where 2nd dimension is xyxy with label and confidence.","title":"predict()"},{"location":"obj_det/#BiWAKO.object_detection.YOLO.render","text":"Return the original image with predicted bounding boxes. Parameters: Name Type Description Default prediction np.ndarray Prediction of the model. required image Image Image to be predicted. Accept str or cv2 image. required Returns: Type Description np.ndarray Image with predicted bounding boxes in cv2 format.","title":"render()"},{"location":"salient_det/","text":"U2Net BiWAKO.segmentation.U2Net ( BaseInference ) Salient object segmentation model. Attributes: Name Type Description IS onnxruntime.InferenceSession Inference session. input_name str Input node name. output_name str Output node name. input_size int Input size. Set to 320. mean List[float] Mean. Set to [0.485, 0.456, 0.406]. std List[float] Standard deviation. Set to [0.229, 0.224, 0.225]. __init__ ( self , model ) special U2Net Inference class. Parameters: Name Type Description Default model Literal[\"basic\", \"mobile\", \"human_seg\", \"portrait\"] Model name. If model has not been downloaded, it will be downloaded automatically. required predict ( self , image ) Return the predicted mask of the image. Parameters: Name Type Description Default image Union[str, np.ndarray] Image in cv2 format or path to image. required Returns: Type Description np.ndarray Predicted mask in cv2 format. render ( self , prediction , image ) Apply the predicted mask to the original image. Parameters: Name Type Description Default prediction np.ndarray Predicted mask in cv2 format. required image Union[str, np.ndarray] Image in cv2 format or path to image. required Returns: Type Description np.ndarray Rendered original image in cv2 format.","title":"Salient Object Segmenation"},{"location":"salient_det/#u2net","text":"","title":"U2Net"},{"location":"salient_det/#BiWAKO.segmentation.U2Net","text":"Salient object segmentation model. Attributes: Name Type Description IS onnxruntime.InferenceSession Inference session. input_name str Input node name. output_name str Output node name. input_size int Input size. Set to 320. mean List[float] Mean. Set to [0.485, 0.456, 0.406]. std List[float] Standard deviation. Set to [0.229, 0.224, 0.225].","title":"U2Net"},{"location":"salient_det/#BiWAKO.segmentation.U2Net.__init__","text":"U2Net Inference class. Parameters: Name Type Description Default model Literal[\"basic\", \"mobile\", \"human_seg\", \"portrait\"] Model name. If model has not been downloaded, it will be downloaded automatically. required","title":"__init__()"},{"location":"salient_det/#BiWAKO.segmentation.U2Net.predict","text":"Return the predicted mask of the image. Parameters: Name Type Description Default image Union[str, np.ndarray] Image in cv2 format or path to image. required Returns: Type Description np.ndarray Predicted mask in cv2 format.","title":"predict()"},{"location":"salient_det/#BiWAKO.segmentation.U2Net.render","text":"Apply the predicted mask to the original image. Parameters: Name Type Description Default prediction np.ndarray Predicted mask in cv2 format. required image Union[str, np.ndarray] Image in cv2 format or path to image. required Returns: Type Description np.ndarray Rendered original image in cv2 format.","title":"render()"},{"location":"style_transfer/","text":"AnimeGAN2 BiWAKO.anime_gan.AnimeGAN ( BaseInference ) Style Transfer GAN trained for Anime. Attributes: Name Type Description model_path str Path to ONNX model file. If the file is automatically downloaded, the destination path is saved to this. model InferenceSession ONNX model. input_name str Name of input node. output_name str Name of output node. input_size int Size of input image. Set to 512. __init__ ( self , model = 'animeGAN512' ) special Initialize AnimeGAN model. Parameters: Name Type Description Default model Literal[ Either path to the downloaded model or name of the model to trigger automatic download. Defaults to \"animeGAN512\". 'animeGAN512' predict ( self , image ) Return the predicted image from the AnimeGAN model. Parameters: Name Type Description Default image Image Image to predict in str or cv2 image format. required Returns: Type Description np.ndarray Predicted image of size 512*512 in cv2 image format render ( self , prediction , image = None , input_size = None , ** kwargs ) Return the predicted image in original size. Parameters: Name Type Description Default prediction np.ndarray Predicted image of size 512*512 in cv2 image format. required image Image Original image passed to predict(). Defaults to None. None input_size Tuple[int, int] Optional tuple of int to resize. Defaults to None. None Exceptions: Type Description ValueError If none of image or input_size is provided. Returns: Type Description np.ndarray Predicted image in original size.","title":"Style Transfer"},{"location":"style_transfer/#animegan2","text":"","title":"AnimeGAN2"},{"location":"style_transfer/#BiWAKO.anime_gan.AnimeGAN","text":"Style Transfer GAN trained for Anime. Attributes: Name Type Description model_path str Path to ONNX model file. If the file is automatically downloaded, the destination path is saved to this. model InferenceSession ONNX model. input_name str Name of input node. output_name str Name of output node. input_size int Size of input image. Set to 512.","title":"AnimeGAN"},{"location":"style_transfer/#BiWAKO.anime_gan.AnimeGAN.__init__","text":"Initialize AnimeGAN model. Parameters: Name Type Description Default model Literal[ Either path to the downloaded model or name of the model to trigger automatic download. Defaults to \"animeGAN512\". 'animeGAN512'","title":"__init__()"},{"location":"style_transfer/#BiWAKO.anime_gan.AnimeGAN.predict","text":"Return the predicted image from the AnimeGAN model. Parameters: Name Type Description Default image Image Image to predict in str or cv2 image format. required Returns: Type Description np.ndarray Predicted image of size 512*512 in cv2 image format","title":"predict()"},{"location":"style_transfer/#BiWAKO.anime_gan.AnimeGAN.render","text":"Return the predicted image in original size. Parameters: Name Type Description Default prediction np.ndarray Predicted image of size 512*512 in cv2 image format. required image Image Original image passed to predict(). Defaults to None. None input_size Tuple[int, int] Optional tuple of int to resize. Defaults to None. None Exceptions: Type Description ValueError If none of image or input_size is provided. Returns: Type Description np.ndarray Predicted image in original size.","title":"render()"},{"location":"super_resolution/","text":"Super Resolution BiWAKO.super_resolution.RealESRGAN ( BaseInference ) Super Resolution model. Attributes: Name Type Description model_path str Path to the model. If automatic download is enabled, it will be downloaded to this path. session rt.InferenceSession ONNX Runtime session. w, h (int Width and height of the model input. input_name str Name of the input node. output_name str Name of the output node. __init__ ( self , model ) special Initialize RealESRGAN. Parameters: Name Type Description Default model Literal[\"super_resolution4864\", \"super_resolution6464\"] Model name. If model has not been downloaded, it will be downloaded automatically. Currently supports [\"super_resolution4864\", \"super_resolution6464\"]. required predict ( self , image ) Return the upscaled image. Parameters: Name Type Description Default image Image Image to be upscaled. Accept path or cv2 image. required Returns: Type Description np.ndarray Upscaled image in cv2 format. render ( self , prediction , image ) Return the upscaled image. This is just a placeholder. Parameters: Name Type Description Default prediction np.ndarray Upscaled image in cv2 format. This image is returned. required image Image Original image. Not used. required Returns: Type Description np.ndarray Upscaled image in cv2 format.","title":"Super Resolution"},{"location":"super_resolution/#super-resolution","text":"","title":"Super Resolution"},{"location":"super_resolution/#BiWAKO.super_resolution.RealESRGAN","text":"Super Resolution model. Attributes: Name Type Description model_path str Path to the model. If automatic download is enabled, it will be downloaded to this path. session rt.InferenceSession ONNX Runtime session. w, h (int Width and height of the model input. input_name str Name of the input node. output_name str Name of the output node.","title":"RealESRGAN"},{"location":"super_resolution/#BiWAKO.super_resolution.RealESRGAN.__init__","text":"Initialize RealESRGAN. Parameters: Name Type Description Default model Literal[\"super_resolution4864\", \"super_resolution6464\"] Model name. If model has not been downloaded, it will be downloaded automatically. Currently supports [\"super_resolution4864\", \"super_resolution6464\"]. required","title":"__init__()"},{"location":"super_resolution/#BiWAKO.super_resolution.RealESRGAN.predict","text":"Return the upscaled image. Parameters: Name Type Description Default image Image Image to be upscaled. Accept path or cv2 image. required Returns: Type Description np.ndarray Upscaled image in cv2 format.","title":"predict()"},{"location":"super_resolution/#BiWAKO.super_resolution.RealESRGAN.render","text":"Return the upscaled image. This is just a placeholder. Parameters: Name Type Description Default prediction np.ndarray Upscaled image in cv2 format. This image is returned. required image Image Original image. Not used. required Returns: Type Description np.ndarray Upscaled image in cv2 format.","title":"render()"}]}